name: Terraform CI/CD

on:
  push:
    branches:
      - master
  pull_request:
    branches:
      - master

jobs:
  terraform:
    runs-on: ubuntu-latest

    defaults:
      run:
        working-directory: src

    steps:
      # Step 1: Checkout the repo
      - name: Checkout code
        uses: actions/checkout@v2

      # Step 2: Configure AWS Credentials
      - name: Configure AWS Credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-session-token: ${{ secrets.AWS_SESSION_TOKEN }}
          aws-region: us-west-2

      # Step 3: Create S3 Bucket for Terraform State
      - name: Create or Retrieve S3 Bucket
        run: |
          PARAM_NAME="/my-terraform/s3-bucket-name"
          EXISTING_BUCKET=$(aws ssm get-parameter --name $PARAM_NAME --query 'Parameter.Value' --output text 2>/dev/null || echo "")

          if [ -z "$EXISTING_BUCKET" ]; then
            # Generate a unique bucket name
            BUCKET_NAME="my-terraform-state-bucket-$(date +%s)"
            echo "No bucket found. Creating a new bucket: $BUCKET_NAME"
            aws s3api create-bucket --bucket $BUCKET_NAME --region us-west-2 --create-bucket-configuration LocationConstraint=us-west-2

            # Save the bucket name in SSM Parameter Store
            aws ssm put-parameter --name $PARAM_NAME --value $BUCKET_NAME --type String --overwrite
          else
            echo "Using existing bucket: $EXISTING_BUCKET"
            BUCKET_NAME=$EXISTING_BUCKET
          fi

          echo "bucket_name=$BUCKET_NAME" >> $GITHUB_ENV



      # Step 4: Create DynamoDB Table for State Locking
      - name: Check or Create DynamoDB Table
        run: |
          TABLE_NAME="my-terraform-lock-table"
          if aws dynamodb describe-table --table-name $TABLE_NAME 2>/dev/null; then
            echo "DynamoDB table $TABLE_NAME already exists. Skipping creation."
          else
            echo "Creating DynamoDB table: $TABLE_NAME..."
            aws dynamodb create-table \
              --table-name $TABLE_NAME \
              --attribute-definitions AttributeName=LockID,AttributeType=S \
              --key-schema AttributeName=LockID,KeyType=HASH \
              --billing-mode PAY_PER_REQUEST
          fi

          echo "dynamodb_table=$TABLE_NAME" >> $GITHUB_ENV



      # Step 5: Create EC2 Key Pairs
      - name: Check or Create EC2 Key Pairs
        run: |
          PRIVATE_KEY_NAME="key-ec2-private"
          PUBLIC_KEY_NAME="key-ec2-public"

          # Check private key
          if aws ec2 describe-key-pairs --key-names $PRIVATE_KEY_NAME 2>/dev/null; then
            echo "Private key $PRIVATE_KEY_NAME already exists. Skipping creation."
          else
            echo "Creating private key pair: $PRIVATE_KEY_NAME..."
            aws ec2 create-key-pair --key-name $PRIVATE_KEY_NAME --query 'KeyMaterial' --output text > $PRIVATE_KEY_NAME.pem
            chmod 400 $PRIVATE_KEY_NAME.pem
          fi

          # Check public key
          if aws ec2 describe-key-pairs --key-names $PUBLIC_KEY_NAME 2>/dev/null; then
            echo "Public key $PUBLIC_KEY_NAME already exists. Skipping creation."
          else
            echo "Creating public key pair: $PUBLIC_KEY_NAME..."
            aws ec2 create-key-pair --key-name $PUBLIC_KEY_NAME --query 'KeyMaterial' --output text > $PUBLIC_KEY_NAME.pem
            chmod 400 $PUBLIC_KEY_NAME.pem
          fi

          echo "private_key_name=$PRIVATE_KEY_NAME.pem" >> $GITHUB_ENV
          echo "public_key_name=$PUBLIC_KEY_NAME.pem" >> $GITHUB_ENV


      # Step 6: Update terraform.tfvars
      - name: Update terraform.tfvars
        run: |
          BUCKET_NAME=$(aws ssm get-parameter --name /my-terraform/s3-bucket-name --query 'Parameter.Value' --output text)
          TABLE_NAME="my-terraform-lock-table"

          # Ensure terraform.tfvars exists and is updated
          if [ ! -f terraform.tfvars ]; then
            touch terraform.tfvars
          fi

          # Update or add the bucket_name
          if grep -q "^s3_bucket_name" terraform.tfvars; then
            sed -i "s/^s3_bucket_name.*/s3_bucket_name = \"$BUCKET_NAME\"/" terraform.tfvars
          else
            echo "s3_bucket_name = \"$BUCKET_NAME\"" >> terraform.tfvars
          fi

          # Update or add the dynamodb_table_name
          if grep -q "^dynamodb_table_name" terraform.tfvars; then
            sed -i "s/^dynamodb_table_name.*/dynamodb_table_name = \"$TABLE_NAME\"/" terraform.tfvars
          else
            echo "dynamodb_table_name = \"$TABLE_NAME\"" >> terraform.tfvars
          fi

          echo "Updated terraform.tfvars with S3 bucket and DynamoDB table names."



      # Step 7: Generate Updated Backend
      - name: Generate Backend Configuration
        working-directory: src
        run: |
          # Retrieve the S3 bucket name from SSM Parameter Store
          BUCKET_NAME=$(aws ssm get-parameter --name /my-terraform/s3-bucket-name --query 'Parameter.Value' --output text)
          TABLE_NAME="my-terraform-lock-table"

          # Generate backend.tf with the correct bucket and table names
          cat <<EOF > backend.tf
          terraform {
            backend "s3" {
              bucket         = "$BUCKET_NAME"
              key            = "terraform/state.tfstate"
              region         = "us-west-2"
              encrypt        = true
              dynamodb_table = "$TABLE_NAME"
              acl            = "bucket-owner-full-control"
            }
          }
          EOF

          echo "Generated backend.tf with S3 bucket $BUCKET_NAME and DynamoDB table $TABLE_NAME."




      # Step 8: Set up Terraform
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.5.0

      # Step 9: Initialize Terraform
      - name: Terraform Init
        run: terraform init


      # Step 10: Terraform Plan
      - name: Terraform Plan
        run: terraform plan

      # Step 11: Terraform Apply
      - name: Terraform Apply
        if: github.event_name == 'push'
        run: terraform apply -auto-approve

       # Step 12: Terraform Destroy
      # - name: Terraform Destroy
       #  working-directory: src
        # run: terraform destroy --auto-approve


       # Step 13: Empty and Delete S3 Bucket
       #- name: Empty and Delete S3 Bucket
        # run: |
           # Retrieve the S3 bucket name from SSM Parameter Store
         #  BUCKET_NAME=$(aws ssm get-parameter --name /my-terraform/s3-bucket-name --query 'Parameter.Value' --output text)

           # Empty the bucket
#           echo "Emptying S3 bucket: $BUCKET_NAME..."
 #          aws s3 rm s3://$BUCKET_NAME --recursive

           # Delete the bucket
  #         echo "Deleting S3 bucket: $BUCKET_NAME..."
   #        aws s3api delete-bucket --bucket $BUCKET_NAME --region us-west-2


       # Step 14: Delete DynamoDB Table
    #   - name: Delete DynamoDB Table
     #    run: |
      #     TABLE_NAME="my-terraform-lock-table"

       #    echo "Deleting DynamoDB table: $TABLE_NAME..."
        #   aws dynamodb delete-table --table-name $TABLE_NAME --region us-west-2


       # Step 15: Delete EC2 Key Pairs
       #- name: Delete EC2 Key Pairs
        # run: |
         #  PRIVATE_KEY_NAME="key-ec2-private"
          # PUBLIC_KEY_NAME="key-ec2-public"

           # Delete private key pair
           #echo "Deleting key pair: $PRIVATE_KEY_NAME..."
           #aws ec2 delete-key-pair --key-name $PRIVATE_KEY_NAME

           # Delete public key pair
           #echo "Deleting key pair: $PUBLIC_KEY_NAME..."
           #aws ec2 delete-key-pair --key-name $PUBLIC_KEY_NAME */

